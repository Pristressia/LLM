{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd48f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207102c6",
   "metadata": {},
   "source": [
    "Transformer ที่ใช้กันในปัจจุบันมี 2 รูปแบบ 1 คือ แบบ post-LN ตามที่ปรากฏใน Attention is all you need \n",
    "และอีกแบบที่นิยมนำมาใช้ใน การสร้างโมเดลขนาดใหญ่ในปัจจุบันคือ Pre-LN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed0bc9c",
   "metadata": {},
   "source": [
    "## 1. ความแตกต่างกันระหว่าง Pre, Post LN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7d0a9a",
   "metadata": {},
   "source": [
    "ให้ $x$ คือ hidden state ($x \\in \\mathbb{R}^{T, d_{model}}$ )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf7fad",
   "metadata": {},
   "source": [
    "#### Post-LN แบบดั้งเดิม\n",
    "---\n",
    "* Attention sublayer:\n",
    "$$y = LN(x + MHA(x))$$\n",
    "* FFN sublayer:\n",
    "$$z = LN(y + FFN(y))$$\n",
    "> จะเห็นได้ว่า หลังบวก residual (Add แล้วค่อย Norm)\n",
    "\n",
    "Where \n",
    "> * LN หมายถึง linear normalized\n",
    "> * MHA หมายถึง multihead attention\n",
    "> * FFN หมายถึง feed-forward neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a01dd",
   "metadata": {},
   "source": [
    "### Pre-LN\n",
    "---\n",
    "* Attention sublayer:\n",
    "$$y = x + MHA(LN(x))$$\n",
    "* FFN sublayer: \n",
    "$$z = y + FFN(LN(y))$$\n",
    "\n",
    "> LN อยู่ก่อน sublayer (Norm ก่อนแล้วคำนวน Attention / FFN แล้วค่อย Add)\n",
    "\n",
    "> **ใน Pre-LN จะมี Final LN อีกที หลังจากผ่าน Transformer stack ก่อนเข้า LM Head เพื่อให้ Scale นิ่ง**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfbee52",
   "metadata": {},
   "source": [
    "### Linear normalized function\n",
    "---\n",
    "$$LN = \\frac {X - \\mu} {\\sigma + \\epsilon} \\cdot \\gamma + \\beta$$\n",
    "\n",
    "Where \n",
    "* $LN$ stand for Linear - Normalized\n",
    "* $X$ stand for $X \\in \\mathbb {R} ^ {T \\times d_{model}}$\n",
    "* $\\mu$ stand for mean of $X$ in $d_{model}$ direction\n",
    "* $\\sigma$ stand for standard derivation of $X$ in $d_{model}$ direction\n",
    "* $\\epsilon$ the minimum value that make this equation not to be divide by zero\n",
    "* $\\gamma$ stand for gaining parameter (trainable)\n",
    "* $\\beta$ stand for shift parameter (trainable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6802652",
   "metadata": {},
   "source": [
    "### Softmax function\n",
    "\n",
    "$$ softmax(x) = \\frac {e^{x - x_{max}}} {\\sum_{i} e^{x_i - x_{max}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb8e0dc",
   "metadata": {},
   "source": [
    "สูตรด้านบนมีข้อควรระวังในเคสถ้าค่าใน X มีความห่างกันมาก ๆ การใช้ $x_{max}$ ของทั้ง matrix จะเกิดปรากฎการณ์ลู่เข้า 0 เหมือนกันหมด อาทิเช่น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e325654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if x =  [ 980  990 1000]\n",
      "e^x =  [2.06115362e-09 4.53999298e-05 1.00000000e+00]\n",
      "if x =  [1 2 3]\n",
      "e^x =  [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_max = 1000\n",
    "x = np.array([980, 990, 1000])\n",
    "print(\"if x = \", x)\n",
    "print(\"e^x = \", np.exp(x - x_max))\n",
    "\n",
    "x = np.array([1, 2, 3])\n",
    "print(\"if x = \", x)\n",
    "print(\"e^x = \", np.exp(x - x_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46a5e25",
   "metadata": {},
   "source": [
    "ดังนั้นจึงแนะนำให้เลือกแนวแกนแล้วทำ softmax ตามแนวแกนนั้น"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb4dd8",
   "metadata": {},
   "source": [
    "### ใน attention ต้องทำ softmax ในแนวแกนไหน ?\n",
    "---\n",
    "* ใน scaled dot-product attention:\n",
    "$$scores = \\frac {Q \\cdot K^\\intercal}{\\sqrt{d_k}}$$\n",
    "\n",
    "* ทำให้ $scores \\in \\mathbb{R}^{t_q \\times t_k}$ หรือใน multi-head คือ $scores \\in \\mathbb{R} ^ {B \\times H \\times t_q \\times t_k}$\n",
    "\n",
    "* เราต้องการให้ \"ต่อ 1 query\" (แต่ละแถวใน $T_k$) เป็น distribution บน keys \n",
    "> **ดังนั้น softmax ต้องทำตามแนวแกน $T_k$ (แกนสุดท้าย)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92928235",
   "metadata": {},
   "source": [
    "## 2. Demo Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16a2b4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c781811",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 6; # hidden states เป็นความยาว array ของแต่ละ token หลังการ embedding\n",
    "\n",
    "H = 2; # จำนวน Attention head\n",
    "d_head = 3 # d_model / H\n",
    "V = 8 # จำนวน Vocab\n",
    "T = 4 # จำนวน Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a03f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2236d0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52138574, 0.60384185, 0.4709418 , 0.20324794, 0.52875903,\n",
       "        0.19103628],\n",
       "       [0.2815456 , 0.75368155, 0.55167178, 0.86372208, 0.80537222,\n",
       "        0.24837266],\n",
       "       [0.18985741, 0.98399558, 0.66999717, 0.28038283, 0.20391323,\n",
       "        0.62506469],\n",
       "       [0.65260432, 0.89880753, 0.97476378, 0.15393237, 0.69908928,\n",
       "        0.44724145]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = rng.random((T, d_model), np.float64)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8470de1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma1 = [0.01751321 0.29102491 0.38123661 0.32102791 0.94254467 0.70266697]\n",
      " beta1 = [0.13645032 0.34320907 0.8119946  0.148494   0.05932569 0.31441663]\n"
     ]
    }
   ],
   "source": [
    "gamma1 = rng.random((d_model), np.float64)\n",
    "beta1 = rng.random((d_model), np.float64)\n",
    "\n",
    "print(\"gamma1 =\", gamma1)\n",
    "print(\" beta1 =\", beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f509cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu =>\n",
      " [[0.41986877]\n",
      " [0.58406098]\n",
      " [0.49220182]\n",
      " [0.63773979]]\n",
      "std =>\n",
      " [[0.16222732]\n",
      " [0.24536075]\n",
      " [0.29169464]\n",
      " [0.27570681]]\n"
     ]
    }
   ],
   "source": [
    "mu = np.mean(X, axis = -1, keepdims=True)\n",
    "std = np.std(X, axis = -1, keepdims=True)\n",
    "\n",
    "print(\"mu =>\\n\", mu)\n",
    "print(\"std =>\\n\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "766c7548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14740956,  0.6732444 ,  0.93201697, -0.28017197,  0.6919807 ,\n",
       "        -0.67674215],\n",
       "       [ 0.11485756,  0.54439777,  0.76166891,  0.51440018,  0.909485  ,\n",
       "        -0.64693146],\n",
       "       [ 0.1182977 ,  0.83387368,  1.04436808, -0.08462584, -0.87221309,\n",
       "         0.63447171],\n",
       "       [ 0.13739453,  0.61878157,  1.27801821, -0.4148424 ,  0.26905803,\n",
       "        -0.17108784]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma1 * ((X - mu) / (std + 1e-9)) + beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66149e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearNorm(X, gamma, beta, eps = 1e-9, axis = -1) :\n",
    "    mu = np.mean(X, axis = axis, keepdims=True)\n",
    "    std = np.std(X, axis = axis, keepdims=True)\n",
    "    return gamma * ((X - mu) / (std + eps)) + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6be64abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14740956,  0.6732444 ,  0.93201697, -0.28017197,  0.6919807 ,\n",
       "        -0.67674215],\n",
       "       [ 0.11485756,  0.54439777,  0.76166891,  0.51440018,  0.909485  ,\n",
       "        -0.64693146],\n",
       "       [ 0.1182977 ,  0.83387368,  1.04436808, -0.08462584, -0.87221309,\n",
       "         0.63447171],\n",
       "       [ 0.13739453,  0.61878157,  1.27801821, -0.4148424 ,  0.26905803,\n",
       "        -0.17108784]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapipe = linearNorm(X, gamma1, beta1)\n",
    "x1 = datapipe.copy()\n",
    "datapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae41fee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14740956,  0.6732444 ,  0.93201697, -0.28017197,  0.6919807 ,\n",
       "        -0.67674215],\n",
       "       [ 0.11485756,  0.54439777,  0.76166891,  0.51440018,  0.909485  ,\n",
       "        -0.64693146],\n",
       "       [ 0.1182977 ,  0.83387368,  1.04436808, -0.08462584, -0.87221309,\n",
       "         0.63447171],\n",
       "       [ 0.13739453,  0.61878157,  1.27801821, -0.4148424 ,  0.26905803,\n",
       "        -0.17108784]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20b15212",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_k1 = rng.random((d_model, d_head), np.float64)\n",
    "W_q1 = rng.random((d_model, d_head), np.float64)\n",
    "W_v1 = rng.random((d_model, d_head), np.float64)\n",
    "\n",
    "W_k2 = rng.random((d_model, d_head), np.float64)\n",
    "W_q2 = rng.random((d_model, d_head), np.float64)\n",
    "W_v2 = rng.random((d_model, d_head), np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "604a20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = X @ W_k1\n",
    "Q1 = X @ W_q1\n",
    "V1 = X @ W_v1\n",
    "\n",
    "K2 = X @ W_k2\n",
    "Q2 = X @ W_q2\n",
    "V2 = X @ W_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55c58078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K1 =>\n",
      " [[1.2527992  1.32075642 0.93814284]\n",
      " [2.05800531 1.85507023 1.76608856]\n",
      " [1.55996752 1.63750765 1.30605614]\n",
      " [1.82642607 1.90086531 1.51556223]]\n",
      "Q1 =>\n",
      " [[1.32297136 0.92811187 0.93688803]\n",
      " [2.01381787 1.24562666 1.68262418]\n",
      " [1.59113101 1.19988588 1.18424662]\n",
      " [1.86500052 1.57009664 1.39953962]]\n",
      "V1 =>\n",
      " [[1.474291   1.37938888 1.13889442]\n",
      " [2.47774422 2.3514763  1.60251449]\n",
      " [1.76324287 1.86219185 1.41314099]\n",
      " [2.17745369 2.00985722 1.87073196]]\n"
     ]
    }
   ],
   "source": [
    "print(\"K1 =>\\n\", K1)\n",
    "print(\"Q1 =>\\n\", Q1)\n",
    "print(\"V1 =>\\n\", V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "840bbef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = Q1 @ K1.T / np.sqrt(d_head)\n",
    "scores2 = Q2 @ K2.T / np.sqrt(d_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63b9e38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores1 => \n",
      " [[2.17208522 3.521272   2.77544456 3.23341389]\n",
      " [3.31781298 5.44258637 4.260161   4.96289114]\n",
      " [2.70726303 4.38319305 3.4604225  4.03088871]\n",
      " [3.30426476 5.324631   4.21942751 4.91435768]]\n"
     ]
    }
   ],
   "source": [
    "print(\"scores1 => \\n\", scores1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c44cd0",
   "metadata": {},
   "source": [
    "### softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78c73f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.521272  ],\n",
       "       [5.44258637],\n",
       "       [4.38319305],\n",
       "       [5.324631  ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1_max = np.max(scores1, axis = -1, keepdims=True) # softmax ตามแนว keys หรือแนวนอน\n",
    "scores1_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ce27c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.34918678  0.         -0.74582743 -0.28785811]\n",
      " [-2.12477339  0.         -1.18242537 -0.47969523]\n",
      " [-1.67593001  0.         -0.92277055 -0.35230434]\n",
      " [-2.02036624  0.         -1.10520349 -0.41027332]]\n"
     ]
    }
   ],
   "source": [
    "dscore1 = scores1 - scores1_max\n",
    "print(dscore1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3df8ec77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1044632 , 0.40263147, 0.19098488, 0.30192045],\n",
       "       [0.05841662, 0.48900559, 0.14989702, 0.30268077],\n",
       "       [0.08180307, 0.43713618, 0.17372511, 0.30733564],\n",
       "       [0.06233814, 0.47009728, 0.15566966, 0.31189492]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmaxResult = np.exp(dscore1)/np.sum(np.exp(dscore1), axis= -1, keepdims = True)\n",
    "softmaxResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef2c5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X, axis = -1) :\n",
    "    X = X - np.max(X, axis = axis, keepdims=True);\n",
    "    eX = np.exp(X)\n",
    "    return eX / np.sum(eX, axis = axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "225d6dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention 1 :\n",
      "[[0.1044632  0.40263147 0.19098488 0.30192045]\n",
      " [0.05841662 0.48900559 0.14989702 0.30268077]\n",
      " [0.08180307 0.43713618 0.17372511 0.30733564]\n",
      " [0.06233814 0.47009728 0.15566966 0.31189492]]\n"
     ]
    }
   ],
   "source": [
    "attn1 = softmax(scores1)\n",
    "print(\"attention 1 :\");\n",
    "print(attn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "549a8bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention 2 :\n",
      "[[0.13172653 0.27212327 0.18301422 0.41313598]\n",
      " [0.09215779 0.25641916 0.1529684  0.49845464]\n",
      " [0.12569073 0.27381841 0.17754409 0.42294677]\n",
      " [0.09610674 0.26572722 0.15079531 0.48737074]]\n"
     ]
    }
   ],
   "source": [
    "attn2 = softmax(scores2)\n",
    "print(\"attention 2 :\");\n",
    "print(attn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75d7905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.14579748 2.05334122 1.59889611]\n",
      " [2.22113208 2.11794643 1.62822912]\n",
      " [2.17924186 2.08196385 1.6141228 ]\n",
      " [2.21030554 2.10816218 1.62778924]]\n"
     ]
    }
   ],
   "source": [
    "output1 = attn1 @ V1\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "184cb265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.61703732 1.08593014 1.76418502]\n",
      " [1.65971009 1.10975219 1.7909971 ]\n",
      " [1.62332767 1.0892788  1.76939115]\n",
      " [1.6566034  1.10739055 1.79149989]]\n"
     ]
    }
   ],
   "source": [
    "output2 = attn2 @ V2\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d96f9a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.14579748 2.05334122 1.59889611 1.61703732 1.08593014 1.76418502]\n",
      " [2.22113208 2.11794643 1.62822912 1.65971009 1.10975219 1.7909971 ]\n",
      " [2.17924186 2.08196385 1.6141228  1.62332767 1.0892788  1.76939115]\n",
      " [2.21030554 2.10816218 1.62778924 1.6566034  1.10739055 1.79149989]]\n"
     ]
    }
   ],
   "source": [
    "datapipe = np.concatenate([output1, output2], axis = -1)\n",
    "print(datapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef969065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
