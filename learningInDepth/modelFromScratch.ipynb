{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb66e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c2857",
   "metadata": {},
   "source": [
    "**all of $log\\left(\\cdot\\right)$ function in this notebook is $log_e \\left(\\cdot \\right)$ or netural log or $ln\\left(\\cdot\\right)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777516e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_token = 5;\n",
    "d_model = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b82b4c8",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac21075",
   "metadata": {},
   "source": [
    "giving a token sequence: \n",
    "$$ x_0, x_1, x_2, ..., x_T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5988ef",
   "metadata": {},
   "source": [
    "We train on pairs:\n",
    "$$(x_0 \\rightarrow x_1), (x_1 \\rightarrow x_2), ..., (x_{T-1} \\rightarrow x_T)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5cc2c",
   "metadata": {},
   "source": [
    "Model output\n",
    "\n",
    "The model outputs a probabiliy distribution over vocabulary $V$:\n",
    "$$p_\\theta \\left(\\cdot | context\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed42f76c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5fd294",
   "metadata": {},
   "source": [
    "Transformer method for text generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e36ba3c",
   "metadata": {},
   "source": [
    "for text generation we use \"*Decoder-only Transformer*\"\n",
    "\n",
    "(marked self-attentino, autoregressive)\n",
    "\n",
    "The lost function is **Always** next-token cross-entropy\n",
    "(no matter how big the model gets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60806827",
   "metadata": {},
   "source": [
    "## Loss function of a Transformer LLM (VERY important)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2144a6bc",
   "metadata": {},
   "source": [
    "Vocabulary \n",
    "Let: \n",
    "* vocab size = V\n",
    "* sequence length = T\n",
    "Model output : \n",
    "\n",
    "$$ logits shape = (T, V) $$\n",
    "each position predicts **the next token**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63fda5",
   "metadata": {},
   "source": [
    "### Cross-entropy loss (formal)\n",
    "---\n",
    "For a single position t : \n",
    "$$L_t = -log \\left(p_\\theta \\left(x_{t+1} | x_{\\leq t}\\right)\\right)$$\n",
    "\n",
    "For a sequence : \n",
    "$$L = \\frac{1}{T} \\sum_{t = 0}^{T - 1} -log \\left(p_\\theta \\left(x_{t+1}\\right)\\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d83a99",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "$p_\\theta \\left( \\cdot \\right)$ คืออะไร?\n",
    "\n",
    "* ความน่าจะเป็นที่โมเดล ซึ่งมีพารามิเตอร์ $\\theta$ ประเมินออกมา\n",
    "โดย\n",
    "\n",
    "* $p$ = probability\n",
    "* $\\theta$ = parameter ทั้งหมดของโมเดล (all of weight and bias in Transformer)  \n",
    "\n",
    "**ใน LLM** :  $$\\theta = \\{Embedding\\ matrices, W_Q, W_K, W_V, ...., \\gamma, \\Beta, ...\\}$$\n",
    "\n",
    "ดังนั้นถ้า $\\theta$ มีค่าเปลี่ยนไป หมายความว่า ความคิดของโมเดลเปลี่ยนไป"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c461630",
   "metadata": {
    "vscode": {
     "languageId": "tex"
    }
   },
   "source": [
    "* $x_{\\leq t}$ มีความหมายถึง $x_0, x_1, x_2, ..., x_t$ หรือ token ทั้งหมดที่เห็นมาแล้ว \n",
    "* $x_{t+1}$ คือ token ตัวถัดไปที่เกิดขึ้นจริง (ground truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46adb797",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\"I love machine ___\"  \n",
    "target = \"learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e19b57",
   "metadata": {},
   "source": [
    "#### $p_\\theta \\left(x_{t+1} | x_{\\leq t}\\right)$\n",
    "* มีความหมายว่า \"ความน่าจะเป็นที่โมเดล (ที่มีพารามิเตอร์ $\\theta$) ให้กับ token ถัดไป $t_{t+1}$ เมื่อเห็น context $x_{\\leq t}$\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06fd1fd",
   "metadata": {},
   "source": [
    "Example :\n",
    "if \n",
    "* vocab = [\"cat\", \"dog\", \"fish\"]\n",
    "* context = \"I like my\"\n",
    "\n",
    "* model calculate and get : p = [0.1, 0.7, 0.2]\n",
    "\n",
    "if the real answer is \"dog\"\n",
    "\n",
    "$$p_\\theta \\left(x_{t+1} = \"dog\"\\right) = 0.7$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61253c86",
   "metadata": {},
   "source": [
    "Why have $-log$ ?\n",
    "\n",
    "Loss: $$L_t = -ln\\left(0.7\\right) \\approx 0.36$$\n",
    "\n",
    "if $$p_\\theta \\left(\"dog\"\\right) = 0.01$$\n",
    "\n",
    "Loss = 4.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8c327",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
