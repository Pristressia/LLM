{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135c3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e6c986",
   "metadata": {},
   "source": [
    "I give the probability at result of softmax will be:\n",
    "$$softmax(logits) = p$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69295ee4",
   "metadata": {},
   "source": [
    "for example I give them value of p in case of we have only 6 word in total vocab:\n",
    "    $$ p =\\begin{bmatrix} 0.1 & 0.2 &0.4 &0.1 &0.0 &0.2 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b82e5eb",
   "metadata": {},
   "source": [
    "and we have the exact result is y :\n",
    "$$y = \\begin{bmatrix} 0 & 0 & 1 & 0 & 0 & 0\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b4c1ed",
   "metadata": {},
   "source": [
    "because y is some constant :\n",
    "$$changing\\_weight\\_q\\_value\\_by =  -\\frac {\\partial\\left(p \\right)}{\\partial q}$$\n",
    "$$changing\\_weight\\_q\\_value\\_by =  -\\frac {\\partial\\left(softmax(logits) \\right)}{\\partial logits} \\cdot \\frac {\\partial\\left(logits \\right)}{\\partial q}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d24c1",
   "metadata": {},
   "source": [
    "from definition of error it should be like:\n",
    "$$Error = {\\left(y - p\\right)}^2$$\n",
    "\n",
    "but we use this function for calculate error instead:\n",
    "$$\\mathcal{L} = - \\sum_{i = 0}^{V} y_i \\log_e \\left(p_i\\right)$$\n",
    "\n",
    "call **\"cross-entropy loss\"**\n",
    "\n",
    "from the value of y จะได้ว่าค่า $\\mathcal{L}$ จะมีค่าเป็น 0 หาก $y = 0$\n",
    "และ $$\\frac{\\partial\\mathcal{L}}{\\partial q} = 0 ; y_i = 0$$ ด้วย"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea089794",
   "metadata": {},
   "source": [
    "from $$\\frac{d}{dx} \\log_a(x) = \\frac {1} {x \\log_e {a}} = \\frac {1} {x \\ln\\left(a\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b804c9",
   "metadata": {},
   "source": [
    "if we want to decrease error by change some value that will be combine into p \n",
    "we will write it to :\n",
    "$$ changing\\_weight\\_q\\_value\\_by = \\frac {\\partial\\mathcal{L}}{\\partial q}$$\n",
    "$$ \\frac {\\partial\\mathcal{L}}{\\partial q} = \\frac {\\partial}{\\partial q} \\left(-\\sum_{i = 0}^V \\left( y_i \\ln \\left(p_i\\right) \\right)\\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ac5c0",
   "metadata": {},
   "source": [
    "from the y array we found that the equation have the value only at $y_i = 1$ then we got \n",
    "$$ \\frac {\\partial\\mathcal{L}}{\\partial q} = -\\sum_{i=0}^V\\frac {\\partial\\left( y_i \\ln(p_i)\\right)}{\\partial p_i} \\cdot \\frac{\\partial p_i} {\\partial q}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2cb887",
   "metadata": {},
   "source": [
    "$$ \\frac {\\partial\\mathcal{L}}{\\partial q} = -\\frac {y_i}{p_i \\ln\\left(e\\right)} \\cdot \\frac{\\partial p_i} {\\partial q}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3679c55",
   "metadata": {},
   "source": [
    "## Softmax derivation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491cb0f7",
   "metadata": {},
   "source": [
    "from softmax equation:\n",
    "$$p_i = softmax(z_i) = \\frac{e^{z_i}}{\\sum_{k = 0}^{V - 1} \\left(e^{z_k}\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f28281",
   "metadata": {},
   "source": [
    "**การหาอนุพันธ์ของ Softmax จะพิเศษกว่าขั้นตอนอื่นเนื่องจาก $softmax\\left(z_i\\right)$ ไม่ได้ขึ้นอยู่กับแค่ $z_i$ แต่จะขึ้นอยู่กับค่าของ logits ทุกตัว\n",
    "ดังนั้น**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd706a1",
   "metadata": {
    "vscode": {
     "languageId": "tex"
    }
   },
   "source": [
    "if $$logits = \\begin{bmatrix}z_0&z_1&...&z_j&...&z_{V - 1}\\end{bmatrix}$$\n",
    "\n",
    "$$\\frac{\\partial p_i} {\\partial z_m} = ?$$\n",
    "if $m = \\begin{matrix} 0, 1,..., V-1 \\end{matrix}$\n",
    "\n",
    "We start with :\n",
    "\n",
    "$$\\frac{d}{dz_m} \\frac{U}{S} = \\frac{U^\\prime S - US^\\prime}{S^2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c53af2c",
   "metadata": {},
   "source": [
    "\n",
    "$$U = e^{z_i}$$\n",
    "and \n",
    "$$S = \\sum_{k=0}^S \\left(e^{z_k}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e771a88",
   "metadata": {},
   "source": [
    "$$\\frac {\\partial U} {\\partial z_m} = \n",
    "\\begin{cases} \n",
    "    e^{z_i} & \\text{if $i = m$}\\\\ \n",
    "    0 & \\text {if $i \\neq m$} \n",
    "\\end{cases}$$\n",
    "**Or**\n",
    "$$\\frac {\\partial U} {\\partial z_m} = e^{z_i}\\delta_{i,m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9eb35",
   "metadata": {},
   "source": [
    "then in case of $i = m$ we got : \n",
    "\n",
    "$$\\frac{\\partial p_i}{\\partial z_m} = \\frac{e^{z_i} S - e^{2\\cdot z_i}}{S^2}$$\n",
    "$$\\frac{\\partial p_i}{\\partial z_m} = \\frac{e^{z_i}}{S} \\cdot \\frac{S - e^{z_i}}{S}$$\n",
    "\n",
    "finally got\n",
    "$$\\frac{\\partial p_i}{\\partial z_m} = p_i \\cdot \\left(1 - p_i\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2e3ed",
   "metadata": {},
   "source": [
    "if $i \\neq m$ :\n",
    "$$\n",
    "    \\frac{\\partial p_i}{\\partial z_m} = \\frac{0 \\cdot S - e^{z_i}e^{z_m}}{V^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial p_i}{\\partial z_m} = -\\frac{e^{z_i}e^{z_m}}{S^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b89868",
   "metadata": {},
   "source": [
    "**Or**\n",
    "$$\\frac{\\partial p_i}{\\partial z_m} = p_i \\cdot \\left(\\delta_{i,m} - p_i\\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a39cb3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b081ca3",
   "metadata": {},
   "source": [
    "## Mixing up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0de248",
   "metadata": {},
   "source": [
    "We have\n",
    "$$\\frac{\\partial p_i}{\\partial z_m} = p_i \\cdot \\left(\\delta_{i, m} - p_j\\right)$$\n",
    "และ loss function (cross-entropy) ต่อ 1 ตำแหน่ง:\n",
    "\n",
    "$$\\mathcal{L} = - \\sum_{i = 0}^{V} y_i \\log_e \\left(p_i\\right)$$\n",
    "\n",
    "โดย y มักจะเป็น one-hot (แต่ derivation นี้ใช้ได้กับ distribution ด้วย)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f1187",
   "metadata": {},
   "source": [
    "#### 1.) เริ่ม chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e69a65",
   "metadata": {},
   "source": [
    "$$\\frac {\\partial \\mathcal {L}} {\\partial z_m} =\n",
    "\\sum_{j=0}^{V - 1} \\frac{\\partial \\mathcal{L}}{\\partial p_i} \\cdot\n",
    "\\frac {\\partial p_i}{\\partial z_m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba9469",
   "metadata": {},
   "source": [
    "หา $\\frac {\\partial \\mathcal{L}}{\\partial p_i}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8566ee",
   "metadata": {},
   "source": [
    "$$\\frac {\\partial \\mathcal{L}}{\\partial p_i} = -\\frac{y_i}{p_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2312882",
   "metadata": {},
   "source": [
    "แทนกลับเข้าไป :\n",
    "$$\\frac {\\partial \\mathcal {L}} {\\partial z_m} =\n",
    "\\sum_{i=0}^{V - 1} \\left(\\left(-\\frac{y_i}{p_i} \\right)\\cdot\n",
    "p_i \\cdot \\left(\\delta_{i, m} - p_i\\right)\\right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59669cb9",
   "metadata": {},
   "source": [
    "ตัด $p_i$ ทิ้ง :\n",
    "$$\\frac {\\partial \\mathcal {L}} {\\partial z_m} =\n",
    "\\sum_{j=0}^{V - 1} \\left(-{y_i}  \\cdot \\left(\\delta_{i, m} - p_i\\right)\\right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e463e7",
   "metadata": {},
   "source": [
    "#### 2.) แยกผลรวมออกเป็น 2 ก้อน (นี่คือจุดที่ \"เคสอื่น ๆ\" จะถูกกินรวม)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b876f6",
   "metadata": {},
   "source": [
    "$$-\\sum_i y_i\\left(\\delta_{i, m} - p_m\\right) = - \\sum_i y_i \\delta_{i, m} + \\sum_i y_i p_m$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df105b0",
   "metadata": {},
   "source": [
    "สังเกตว่า $p_m$ ไม่ขึ้นกับ $i$ (สำหรับการ sum ตาม $i$) จึงสามารถดึงออกมาจากผลรวมได้:\n",
    "\n",
    "$$ \\frac {\\partial \\mathcal{L}} {\\partial z_m} = -\\sum_i y_i \\delta_{i, m} + p_m \\sum_i y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f39dc",
   "metadata": {},
   "source": [
    "#### 3.) ประเมินผลรวมของ $\\sum_i y_i \\delta_{i,m}$ และ $\\sum_i y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ffd49d",
   "metadata": {},
   "source": [
    "* $\\sum_i y_i \\delta_{i, m}$ : $\\delta_{i, m}$ ทำหน้าที่ \"เลือก\" เฉพาะตำแหน่ง $i = m$ ดังนั้น : \n",
    "$$ \\sum_i y_i \\delta_{i, m} = y_m$$\n",
    "\n",
    "* $\\sum_i y_i$ : ไม่ว่า $y$ เป็น one-hot หรือจะเป็น probability distribution จะมีค่าผลรวมเท่ากับ 1 เสมอ ดังนั้น :\n",
    "$$ \\sum_i y_i = 1$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7de06f",
   "metadata": {},
   "source": [
    "#### 4.) สรุปออกมาเป็น $p-y$\n",
    "\n",
    "แทนค่า : \n",
    "$$\\frac{\\partial \\mathcal {L}} {\\partial z_m} = -y_m + p_m \\cdot 1 = p_m - y_m$$\n",
    "\n",
    "ดังนั้นในรูป vector : \n",
    "$$\\frac{\\partial \\mathcal {L}} {\\partial \\vec{z}} = \\vec{p}- \\vec{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cac135",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e50c7",
   "metadata": {},
   "source": [
    "## Learn from dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645bf174",
   "metadata": {},
   "source": [
    "สมมุติในการเทรน LLM เราจะมีข้อความหนึ่งชุด แล้วตัดเป็นชิ้นยาว T = 8 tokens:\n",
    "* ถ้าใน 1 step เราใช้ข้อความแค่ชิ้นเดียว -> Batch size $B = 1$\n",
    "    * input shape: (1, 8)\n",
    "    * model จะทำนาย next-token 8 ตำแหน่ง\n",
    "    * จำนวน token ที่ฝึกต่อ step = $B \\cdot T = 8$ \n",
    "\n",
    "ตัวอย่าง batch จริง ๆ (หลายชิ้นพร้อมกัน)\n",
    "\n",
    "สมมติเราเตรียมชิ้นข้อความ (แต่ละชิ้นยาว 8 tokens) ได้ 4 ชิ้น : \n",
    "* Step หนึ่งใช้ 4 ชิ้นพร้อมกัน -> Batch size $B = 4$\n",
    "    * input shape: (4, 8)\n",
    "    * จำนวน token ที่ฝึกต่อ step = $4 \\cdot 8 = 32$\n",
    "\n",
    "**ผลที่ได้คือ** : gradient ที่ได้ต่อ step จะมีความนิ่งขึ้น เพราะมาจากตัวอย่างที่มากขึ้น"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca7a8b",
   "metadata": {},
   "source": [
    "\n",
    "* ตอนที่เราทำการเทรนทีละ Sequence หรือ ฺ$B = 1$ ใช้สมการเดิมได้ไม่มีปัญหา\n",
    "\n",
    "* แต่ถ้าเอา 32 sequence มารวมกันเป็น batch -> $B = 32$\n",
    "\n",
    "ทำให้ shape ที่ได้เป็น : \n",
    "\n",
    "* logits $Z: (B, T, V)$\n",
    "* probs $P: (B, T, V)$\n",
    "* targets $Y: (B, T, V)$ (one-hot) หรือ (B, T)(index)\n",
    "\n",
    "---\n",
    "\n",
    "ทำให้ตอนคิด Loss function จะต้องคิดเป็นค่าเฉลี่ย (mean) (เป็นที่นิยมใช้) แล้วได้สมการเป็น\n",
    "\n",
    "$$\\mathcal {L} = \\frac {1} {B \\cdot T} \\sum_{b=1}^B \\sum_{t=1}^T \\left(-ln \\left(p_{b, t, y_{b,t}}\\right)\\right)$$\n",
    "\n",
    "แล้วทำให้ gradient มี factor $\\frac {1} {B \\cdot T}$ ติดมาด้วย : \n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}} {\\partial \\vec{Z}} = \\frac{\\vec{P} - \\vec{Y}}{B \\cdot T} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f33ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis = -1):\n",
    "\n",
    "    # หาค่ามากสุดตามแนวแกนที่เลือกมาแล้วหักลบกับแต่ละค่าในแมทริกส์\n",
    "    # axis = -1 : [1, 2, 3], [4, 5, 6] -> (2, 3) shape \n",
    "    # ได้คำตอบเป็น [[3], [6]] ที่เป็นค่ามากสุดแต่ละค่าตามแนวแกน X\n",
    "    x = x - np.max(x, axis = axis, keepdims=True)\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e, axis = axis, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0edea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5cbcedb",
   "metadata": {},
   "source": [
    "### 1) for example Vocab มี 6 ตัว\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2754bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab = [\"<PAD>\", \"I\", \"You\", \"love\", \"a\", \"cat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a2774",
   "metadata": {},
   "source": [
    "มีทั้งหมด 2 ประโยค (Batch size $B = 2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93a66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceA = \"I love a cat\"\n",
    "sentenceB = \"You love a cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf20c2",
   "metadata": {},
   "source": [
    "เราจะตั้ง sequence length ที่ใช้เทรนเป็น $T = 3$ (เอาแค่ 3 ตัวแรกเป็น input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df11206",
   "metadata": {},
   "source": [
    "### 2 สร้าง X (input) และ Y (output) ด้วยการเลื่อนไปทางซ้าย 1 ระดับ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb05416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = [1, 3, 4]\n",
    "Y_a = [3, 4, 5]\n",
    "\n",
    "X_b = [2, 3, 4]\n",
    "Y_b = [3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c73fe",
   "metadata": {},
   "source": [
    "### 3) เขียนเป็น Matrix (B, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a6b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([X_a, X_b]);\n",
    "Y = np.array([Y_a, Y_b]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824f76be",
   "metadata": {},
   "source": [
    "### 4) Model ให้ logits ออกมาเป็น (B, T, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d921df7",
   "metadata": {},
   "source": [
    "$Z$ หรือ logits หมายถึงคะแนนดิบก่อน softmax\n",
    "$$ Z \\in \\mathbb{R}^{2 \\times 3 \\times 6}$$\n",
    "ในกรณีนี้\n",
    "* มี ฺBatch size = 2 \n",
    "* มี token size = 3 \n",
    "* มี Vocab size (V) = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda70d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_0 = np.array([\n",
    "    [-1, .2, -.3, 2.5, .1, -.7],\n",
    "    [-.4, -.2, -.5, .1, 2.2, 0],\n",
    "    [-.8, -.3, -.2, 0, .4, 2.6]\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c02b06e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_1 = np.array([\n",
    "    [-1.1, -.1, 0, 2.3, .2, -.6], \n",
    "    [-.5, -.3, -.4, .2, 2.4, -.1],\n",
    "    [-.9, -.4, -.1, .1, .3, 2.5]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b9cbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = np.array([Z_0, Z_1])\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586fff32",
   "metadata": {},
   "source": [
    "### 5) softmax ให้ได้รูปแบบ $P (B, T, V)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a91e9535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.02282931 0.07579597 0.04597258 0.75600279 0.06858303 0.03081634]\n",
      "  [0.05068289 0.06190422 0.04585978 0.08356196 0.68238116 0.07560999]\n",
      "  [0.02501213 0.04123803 0.04557508 0.05566552 0.0830432  0.74946603]]\n",
      "\n",
      " [[0.02380694 0.06471396 0.07151999 0.7133534  0.08735471 0.039251  ]\n",
      "  [0.03998993 0.04884381 0.04419571 0.08052983 0.72678277 0.05965796]\n",
      "  [0.02446378 0.04033395 0.05444514 0.06649944 0.0812226  0.73303509]]]\n"
     ]
    }
   ],
   "source": [
    "P = softmax(Z)\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b900e2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2886e3ad",
   "metadata": {},
   "source": [
    "**Structure of P และทำไมถึงใช้วิธีการหยิบค่ามาคำนวณได้เลย**\n",
    "\n",
    "current output of P consist of 2 batch (index = 0 of shape)\n",
    "ความน่าจะเป็นของโทเคนที่จะออกถัดไปของแต่ละ x ใน index = 1 of shape \n",
    "* ยกตัวอย่างของ batch ที่ 1 (P[0]) เราจะได้ว่าผลการเดาโทเคนตัวต่อไปของคำว่า I คือ (love, มีค่าความน่าจะเป็น P[0, 0, 3] = 0.75600279) \n",
    "    - แต่จาก one hot Y vector คำตอบที่ถูกต้องจะเป็น $Y = \\begin{bmatrix} 0 & 0 & 0 & 1 & 0 & 0 \\end{bmatrix}$\n",
    "    - จากสมการเต็ม\n",
    "    $$ \\mathcal{L} = \\frac{1} {B \\cdot T} \\sum_{b=0}^{B-1} \\sum_{t=0}^{T-1} y_t \\ln \\left(p_t\\right)$$\n",
    "    - แต่ที่ $Y_{t \\neq ตำแหน่งคำตอบที่ถูกต้อง} = 0$ จึงทำให้สมการลดรูปเหลือ\n",
    "    $$ \\mathcal{L} = \\frac{1} {B \\cdot T} \\sum_{b, t} - \\ln \\left(P[b, t, Y[b, T]]\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa01a4db",
   "metadata": {},
   "source": [
    "### 6) คิด loss ด้วย Y (target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ead269a",
   "metadata": {},
   "source": [
    "เพราะ Y เก็บเป็น id ไม่ใช่ one-hot ทำให้เราคิด cross-entropy แบบหยิบเฉพาะคำ\n",
    "\n",
    "$$ \\mathcal{L} = \\frac{1} {B \\cdot T} \\sum_{b, t} -ln \\left(P[b, t, Y[b, t]]\\right)$$\n",
    "\n",
    "ตัวอย่างการหยิบค่ามาคิด loss\n",
    "\n",
    "* สำหรับ A ที่ $t=0$ : target คือ $Y[0, 0] = 3$ (love) -> ใช้ค่า $P[0, 0, 3]$\n",
    "* สำหรับ A ที่ $t=1$ : target คือ $Y[0, 1] = 4$ (a) -> ใช้ค่า $P[0, 1, 4]$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60535a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0.7560027866558934\n"
     ]
    }
   ],
   "source": [
    "print(Y[0, 0])\n",
    "print(P[0, 0, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edd4ed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ของรอบนี้คือ  0.31962317909320725\n"
     ]
    }
   ],
   "source": [
    "B = P.shape[0] #total batch\n",
    "T = P.shape[1] #total token in each step\n",
    "\n",
    "totalLoss = 0\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        totalLoss += - np.log(P[b, t, Y[b, t]])\n",
    "Loss = totalLoss / (B * T)\n",
    "\n",
    "print(\"Loss ของรอบนี้คือ \", Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc87bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5313d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 5\n",
    "T = 6\n",
    "V = 20\n",
    "\n",
    "p = np.array([\n",
    "    [.1, .2, .4, .1, 0, .1], \n",
    "    [.1, .1, .2, 0, 5, .1]]);\n",
    "y = np.array([\n",
    "    [0, 0, 1, 0, 0, 0], \n",
    "    [0, 0, 0, 0, 1, 0]\n",
    "    ]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fa7a58",
   "metadata": {},
   "source": [
    "$$\\text{softmax}\\left(\\text{logits}\\right) =  \\frac{e^{logits_i-logits_{max}}}{\\sum_{i = 0}^{V-1} e^{logits_i-logits_{max}}}$$\n",
    "\n",
    "When $V$ is vocab size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d0b9a",
   "metadata": {},
   "source": [
    "### 7) แล้ว Gradient of logits จะเขียนได้ดังนี้"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24816eca",
   "metadata": {},
   "source": [
    "$$ \\frac {\\partial \\mathcal {L}} {\\partial Z} = \\frac {P - Y_{onehot}} {B \\cdot T} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb25a6",
   "metadata": {},
   "source": [
    "วิธีด้านล่างนี้ผิด ==>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7670cc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of logits ในการคำนวณรอบนี้คือ  -3.2731631266786043\n"
     ]
    }
   ],
   "source": [
    "#find gradient of logits\n",
    "B = P.shape[0]\n",
    "T = P.shape[1]\n",
    "\n",
    "\n",
    "# วิธีนี้ผิด\n",
    "totalGradientOfLogits = 0\n",
    "\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        totalGradientOfLogits += P[b, t, Y[b, t]] - Y[b,t]\n",
    "\n",
    "GradientOfLogits = totalGradientOfLogits / (B * T)\n",
    "print (\"Gradient of logits ในการคำนวณรอบนี้คือ \", GradientOfLogits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134d75a0",
   "metadata": {},
   "source": [
    "#### วิธีที่ถูกต้อง ==>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95afd80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ได้ Onehot of Y เป็น\n",
      "[[[0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "# แบบใช้ one hot vector Y\n",
    "\n",
    "B, T = Y.shape\n",
    "V = P.shape[2]\n",
    "\n",
    "Y_onehot = np.zeros((B, T, V), dtype=np.float64)\n",
    "Y_onehot[np.arange(B)[:, None], np.arange(T)[None, :], Y] = 1.0\n",
    "\n",
    "print(\"ได้ Onehot of Y เป็น\")\n",
    "print(Y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0499a674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "แล้วได้ Gradient of logits เป็น \n",
      "[[[ 0.00380488  0.01263266  0.0076621  -0.0406662   0.0114305\n",
      "    0.00513606]\n",
      "  [ 0.00844715  0.01031737  0.0076433   0.01392699 -0.05293647\n",
      "    0.01260166]\n",
      "  [ 0.00416869  0.00687301  0.00759585  0.00927759  0.01384053\n",
      "   -0.04175566]]\n",
      "\n",
      " [[ 0.00396782  0.01078566  0.01192    -0.04777443  0.01455912\n",
      "    0.00654183]\n",
      "  [ 0.00666499  0.00814063  0.00736595  0.01342164 -0.04553621\n",
      "    0.00994299]\n",
      "  [ 0.0040773   0.00672233  0.00907419  0.01108324  0.0135371\n",
      "   -0.04449415]]]\n"
     ]
    }
   ],
   "source": [
    "GradientOfLogits = (P - Y_onehot) / (B * T)\n",
    "\n",
    "print(\"แล้วได้ Gradient of logits เป็น \")\n",
    "print(GradientOfLogits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00070228",
   "metadata": {},
   "source": [
    "จะเห็นได้ว่า gradient ของ lost function และ softmax (gradient ของ logits) $\\frac {\\partial \\mathcal {L} } {\\partial P} \\cdot \\frac {\\partial P} {\\partial Z}$ รวมกันมีมิติ เท่ากับ logits\n",
    "\n",
    "$$\\frac {\\partial \\mathcal {L}} {\\partial Z} \\in \\mathbb {R} ^ {B \\times T \\times V}$$\n",
    "\n",
    "Where \n",
    "* $B$ is batch size\n",
    "* $T$ is token size\n",
    "* $V$ is vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac1afd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 6)\n",
      "[[[ 0.00380488  0.01263266  0.0076621  -0.0406662   0.0114305\n",
      "    0.00513606]\n",
      "  [ 0.00844715  0.01031737  0.0076433   0.01392699 -0.05293647\n",
      "    0.01260166]\n",
      "  [ 0.00416869  0.00687301  0.00759585  0.00927759  0.01384053\n",
      "   -0.04175566]]\n",
      "\n",
      " [[ 0.00396782  0.01078566  0.01192    -0.04777443  0.01455912\n",
      "    0.00654183]\n",
      "  [ 0.00666499  0.00814063  0.00736595  0.01342164 -0.04553621\n",
      "    0.00994299]\n",
      "  [ 0.0040773   0.00672233  0.00907419  0.01108324  0.0135371\n",
      "   -0.04449415]]]\n"
     ]
    }
   ],
   "source": [
    "# index target method\n",
    "\n",
    "B, T, V = P.shape\n",
    "\n",
    "dZ = P.copy()\n",
    "dZ /= (B * T)\n",
    "\n",
    "# subtract 1/(B * T) at the true class indices\n",
    "\n",
    "dZ[np.arange(B)[:, None], np.arange(T)[None, :], Y] -= 1.0 / (B * T)\n",
    "\n",
    "print (dZ.shape)\n",
    "print(dZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d062631",
   "metadata": {},
   "source": [
    "## Padding and loss mark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d375e",
   "metadata": {},
   "source": [
    "Loss mark คือ ตัวกรองว่า ตำแหน่งไหน ใน Sequence ที่เราจะนำไปคิด Loss และตำแหน่งไหน ไม่คิด  \n",
    "\n",
    "**โดยจะใช้ตอนคำนวณ Loss เท่านั้นไม่คิดใน attention**\n",
    "\n",
    "**Loss mark ใช้ทำอะไรบ้าง**\n",
    "\n",
    "1. กัน PAD ไม่ให้ถูกเอาไปคิด loss\n",
    "\n",
    "เวลา batch ประโยคยาวไม่เท่ากัน เราต้อง pad ให้ยาวเท่ากันเช่นการใส่ <PAD> = id 0 ตำแหน่งที่ PAD ไม้ใช่ข้อมูลจริง -> *ไม่ควรคิด loss*\n",
    "\n",
    "2. Instruction tuning / Chat format\n",
    "\n",
    "เรามัก ไม่อยากให้โมเดลเรียนรู้การทวน Prompt เราอยากให้เรียนเฉพาะคำตอบ (assistanct)\n",
    "เลย mark ตำแหน่ง prompt = 0 และคำตอบ = 1\n",
    "\n",
    "3. Ignore special tokens\n",
    "\n",
    "เช่น <BOS> <SEP> หรือบางคำที่ไม่อยากให้ train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d15f4",
   "metadata": {},
   "source": [
    "### Shape of loss mark "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e985bb9a",
   "metadata": {},
   "source": [
    "loss mark มักจะมี shape เดียวกับ target tokens:\n",
    "* $Y \\in \\mathbb {R} ^ {B \\times T}$\n",
    "* $loss\\_mark \\in \\left\\{1, 0\\right\\} ^ {B \\times T}$ และมีค่าข้างในแค่ 0 และ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d67ca1",
   "metadata": {},
   "source": [
    "### สูตรคำนวณ loss แบบมี mask "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5aefc",
   "metadata": {},
   "source": [
    "$$\\mathcal {L} = \\frac {\\sum_{b,t} m_{b, t} \\cdot \\left(-log \\left( P [b, t, Y[b, t]]\\right)\\right)} {\\sum_{b, t} m_{b, t}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5388e345",
   "metadata": {},
   "source": [
    "### 1) Demo data\n",
    "---\n",
    "* token ที่เป็น system / user / prompt &rarr; mask = 0\n",
    "* token ที่เป็น assistant response &rarr; mask = 1\n",
    "\n",
    "ในขั้นตอนของการ tokenization ถ้ารู้ช่วง index ของ assistant เช่นช่วง $\\left[ start : end \\right)$ สามารถใช้คำสั่ง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c95748b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#focus ที่ mask y\n",
    "\n",
    "start = 0;\n",
    "end = 2\n",
    "loss_mask = np.zeros((B, T), dtype=np.float64)\n",
    "loss_mask[b, start: end] = 1\n",
    "\n",
    "print(loss_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04be7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mask1 = [3, 4, 5] #love a cat\n",
    "Y_mask1 = [4, 5, 0] #a cat <PAD>\n",
    "\n",
    "X_mask2 = [4, 5, 0] #a cat <PAD>\n",
    "Y_mask2 = [5, 0, 0] #cat <PAD> <PAD>\n",
    "\n",
    "pad_id = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b676449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 5 0]\n",
      " [5 0 0]]\n"
     ]
    }
   ],
   "source": [
    "Y = np.array([Y_mask1, Y_mask2]);\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9784a36",
   "metadata": {},
   "source": [
    "loss_mask (1 เฉพาะตำแหน่งที่ไม่ใช่ PAD)\n",
    "\n",
    "> * m คือ loss mask matrix\n",
    "> * M คือ จำนวน token ทั้งหมดที่จะถูกนำไปเทรน"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68e0a2",
   "metadata": {},
   "source": [
    "กติกา: ตำแหน่ง Y == pad_id -> mask = 0 (ไม่คิด loss)\n",
    "ตำแหน่งที่ Y != pad_id -> mask = 1 (คิด loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7233eb",
   "metadata": {},
   "source": [
    "จำนวนตำแหน่งที่คิด loss ทั้งหมด\n",
    "$$M = \\sum loss\\_mask = 3$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "002ff08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ถ้าค่าใน Y ไม่เท่ากับ pad_id (0) จะได้เป็นค่า 1 นอกนั้น 0\n",
    "m = (Y != pad_id).astype(np.float64) # (B, T)\n",
    "M = m.sum()\n",
    "\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e73f8",
   "metadata": {},
   "source": [
    "สมมุติ logits $ Z \\in \\mathbb {R} ^ {B \\times T \\times V}$ \n",
    "\n",
    "**ปรกติเลขที่ได้จะไม่ใช่ 0 ล้วนแต่เพื่อให้ง่ายต่อการมองเห็นภาพ โดยปรกติแล้วตำแหน่งของเลขที่มากที่สุดจะหมายถึง ความน่าจะเป็นที่ token ถัดไปจะออก**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0fd5f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.  0.  0.  0.  1.  0. ]\n",
      "  [0.  0.  0.  0.  0.  2. ]\n",
      "  [0.  0.  0.  0.  0.  0. ]]\n",
      "\n",
      " [[0.  0.  0.  0.  0.  0.5]\n",
      "  [0.  0.  0.  0.  0.  0. ]\n",
      "  [0.  0.  0.  0.  0.  0. ]]]\n"
     ]
    }
   ],
   "source": [
    "Z = np.zeros((B, T, V), dtype=np.float64)\n",
    "\n",
    "Z[0, 0, 4] = 1.0 # (b0, t0) target 4\n",
    "Z[0, 1, 5] = 2.0 # (b0, t1) target 5\n",
    "Z[1, 0, 5] = 0.5 # (b1, t0) target 5\n",
    "\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506bafb6",
   "metadata": {},
   "source": [
    "นำค่า logits ที่ได้ไปหาค่าความน่าจะเป็น $P$ โดยใช้ softmax function &rarr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c447c2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.12956251 0.12956251 0.12956251 0.12956251 0.35218743 0.12956251]\n",
      "  [0.0807164  0.0807164  0.0807164  0.0807164  0.0807164  0.596418  ]\n",
      "  [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]]\n",
      "\n",
      " [[0.15040486 0.15040486 0.15040486 0.15040486 0.15040486 0.24797569]\n",
      "  [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "  [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]]]\n"
     ]
    }
   ],
   "source": [
    "P = softmax(Z)\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834979a2",
   "metadata": {},
   "source": [
    "one-hot matrix Y &rarr; Y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58d178c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "Y_onehot = np.zeros((B, T, V), dtype=np.float64)\n",
    "Y_onehot[np.arange(B)[:, None], np.arange(T)[None, :], Y] = 1.0\n",
    "\n",
    "print(Y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85213a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', 'I', 'You', 'love', 'a', 'cat']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabc371",
   "metadata": {},
   "source": [
    "[[[0. 0. 0. 0. 1. 0.] >> คำต่อไปที่จะออกคือ \"a\"  \n",
    "  [0. 0. 0. 0. 0. 1.] >> คำต่อไปที่จะออกคือ \"cat\"  \n",
    "  [1. 0. 0. 0. 0. 0.]] >> คำต่อไปที่จะออกคือ \"PAD\"  \n",
    "\n",
    " [[0. 0. 0. 0. 0. 1.]  \n",
    "  [1. 0. 0. 0. 0. 0.]  \n",
    "  [1. 0. 0. 0. 0. 0.]]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97bda337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_correct ->\n",
      " [[0.35218743 0.596418   0.16666667]\n",
      " [0.24797569 0.16666667 0.16666667]]\n",
      "loss :  0.98494327816074\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#สร้าง array ใหม่โดยใช้วิธีการหยิบค่าจาก p_correct โดยที่\n",
    "\n",
    "#p_correct[0, 0] หมายถึงเข้าไปหยิบค่ามาจาก P[0, 0, Y[0, 0]]\n",
    "#p_correct[1, 2] หมายถึงเข้าไปหยิบค่ามาจาก P[1, 2, Y[1, 2]]\n",
    "p_correct = P[np.arange(B)[:, None], np.arange(T)[None, :], Y] # (B, T)\n",
    "print(\"p_correct ->\\n\", p_correct);\n",
    "\n",
    "nll = -np.log(p_correct + 1e-12) # เลข 1e-12 ใส่มาเพื่อกัน log (0)\n",
    "loss = (nll * m).sum() / max(M, 1)\n",
    "print(\"loss : \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786d4373",
   "metadata": {},
   "source": [
    "#### วิธีการคำนวน A : $\\frac{\\partial \\mathcal {L} } {\\partial Z} = \\frac {\\left(P - Y_{one-hot}\\right)\\ *\\ m[:, :, None] } {M}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4553a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.0431875   0.0431875   0.0431875   0.0431875  -0.21593752\n",
      "    0.0431875 ]\n",
      "  [ 0.02690547  0.02690547  0.02690547  0.02690547  0.02690547\n",
      "   -0.13452733]\n",
      "  [-0.          0.          0.          0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.05013495  0.05013495  0.05013495  0.05013495  0.05013495\n",
      "   -0.25067477]\n",
      "  [-0.          0.          0.          0.          0.\n",
      "    0.        ]\n",
      "  [-0.          0.          0.          0.          0.\n",
      "    0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "dZ = (P - Y_onehot) * m[:, :, None]\n",
    "dZ = dZ / max(M, 1)\n",
    "print (dZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81c7827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_mark m = \n",
      " [[1. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "M =  3.0\n",
      "masked_loss =  0.98494327816074\n",
      "\n",
      "dZ[0, 0, :] = [ 0.0431875   0.0431875   0.0431875   0.0431875  -0.21593752  0.0431875 ]\n",
      "dZ[0, 1, :] = [ 0.02690547  0.02690547  0.02690547  0.02690547  0.02690547 -0.13452733]\n",
      "dZ[0, 2, :] = [-0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"loss_mark m = \\n\", m) \n",
    "print(\"M = \", M)\n",
    "print(\"masked_loss = \", loss)\n",
    "\n",
    "print(\"\\ndZ[0, 0, :] =\", dZ[0, 0, :])\n",
    "print(\"dZ[0, 1, :] =\", dZ[0,1,:])\n",
    "print(\"dZ[0, 2, :] =\", dZ[0,2,:])  # PAD target -> mask=0 -> should be all zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee57dc1a",
   "metadata": {},
   "source": [
    "จะเห็นได้ว่าตำแหน่งที่ถูก mask ไว้ (Y = PAD) &rarr; $m = 0$  &rarr; $dZ = 0$  \n",
    "\n",
    "ทำให้ทั้ง Vocab &rarr; weight upstream ไม่โดน Update จากตำแหน่งนั้นเลย"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d6d8ed",
   "metadata": {},
   "source": [
    "#### วิธีการคำนวณ B : index trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa195016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 0],\n",
       "       [5, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae55caf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = \n",
      " [[[0.12956251 0.12956251 0.12956251 0.12956251 0.35218743 0.12956251]\n",
      "  [0.0807164  0.0807164  0.0807164  0.0807164  0.0807164  0.596418  ]\n",
      "  [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]]\n",
      "\n",
      " [[0.15040486 0.15040486 0.15040486 0.15040486 0.15040486 0.24797569]\n",
      "  [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "  [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]]]\n",
      "\n",
      "\n",
      "dZ => \n",
      " [[[ 0.0431875   0.0431875   0.0431875   0.0431875  -0.21593752\n",
      "    0.0431875 ]\n",
      "  [ 0.02690547  0.02690547  0.02690547  0.02690547  0.02690547\n",
      "   -0.13452733]\n",
      "  [-0.          0.          0.          0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.05013495  0.05013495  0.05013495  0.05013495  0.05013495\n",
      "   -0.25067477]\n",
      "  [-0.          0.          0.          0.          0.\n",
      "    0.        ]\n",
      "  [-0.          0.          0.          0.          0.\n",
      "    0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "dZ = P.copy()\n",
    "B, T, V = P.shape\n",
    "M = m.sum()\n",
    "\n",
    "\n",
    "print(\"P = \\n\", P)\n",
    "\n",
    "\n",
    "# subtract 1 at the true class indices\n",
    "dZ[np.arange(B)[:, None], np.arange(T)[None, :], Y ] -= 1.0\n",
    "\n",
    "# apply mask and normalize\n",
    "dZ *= m[:, :, None]\n",
    "dZ /= max(M, 1) # avoid division by zero\n",
    "print(\"\\n\\ndZ => \\n\", dZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1f6b28",
   "metadata": {},
   "source": [
    "### ทำไมตอนใส่ loss mask เราใช้แค่ M ในการ normalize ไม่ใช่ B * T หรือ M * B * T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee746e4b",
   "metadata": {},
   "source": [
    "> เป้าหมายในการ normalize คือให้ loss / gradient เป็น average ต่อ 1 token ที่ถูก train ซึ่งจำนวน token ที่ถูก train คือ $M = \\sum m$\n",
    "\n",
    "**กันสับสน ตำแหน่งที่ถูก train จะมีค่าเท่ากับ 1 ใน loss mask matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03708ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7902c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c72edde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99d7c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "loss_mask = np.array([[1, 1, 0], [1, 0, 0]])\n",
    "print(loss_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1794e733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3efe72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_head_forward(H, W, b):\n",
    "    #H: (T, d), W: (d, V), b: (V,)\n",
    "    Z = H @ W + b # (T, V) probs\n",
    "    P = softmax(Z, axis = 1) # (T, V) probs\n",
    "\n",
    "    return Z, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "295c097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossAndSoftmaxBackward(y, p):\n",
    "    return p - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83f63a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1,  0.2, -0.6,  0.1,  0. ,  0.1],\n",
       "       [ 0.1,  0.1,  0.2,  0. ,  4. ,  0.1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlossBydz = lossAndSoftmaxBackward(y, p)\n",
    "dlossBydz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7875f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
