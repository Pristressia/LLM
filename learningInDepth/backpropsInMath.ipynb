{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135c3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e6c986",
   "metadata": {},
   "source": [
    "I give the probability at result of softmax will be:\n",
    "$$softmax(logits) = p$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69295ee4",
   "metadata": {},
   "source": [
    "for example I give them value of p in case of we have only 6 word in total vocab:\n",
    "    $$ p =\\begin{bmatrix} 0.1 & 0.2 &0.4 &0.1 &0.0 &0.2 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b82e5eb",
   "metadata": {},
   "source": [
    "and we have the exact result is y :\n",
    "$$y = \\begin{bmatrix} 0 & 0 & 1 & 0 & 0 & 0\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b4c1ed",
   "metadata": {},
   "source": [
    "because y is some constant :\n",
    "$$changing\\_weight\\_q\\_value\\_by =  -\\frac {\\partial\\left(p \\right)}{\\partial q}$$\n",
    "$$changing\\_weight\\_q\\_value\\_by =  -\\frac {\\partial\\left(softmax(logits) \\right)}{\\partial logits} \\cdot \\frac {\\partial\\left(logits \\right)}{\\partial q}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d24c1",
   "metadata": {},
   "source": [
    "from definition of error it should be like:\n",
    "$$Error = {\\left(y - p\\right)}^2$$\n",
    "\n",
    "but we use this function for calculate error instead:\n",
    "$$\\mathcal{L} = - \\sum_{i = 0}^{V} y_i log \\left(p_i\\right)$$\n",
    "\n",
    "call **\"cross-entropy loss\"**\n",
    "\n",
    "from the value of y จะได้ว่าค่า $\\mathcal{L}$ จะมีค่าเป็น 0 หาก $y = 0$\n",
    "และ $$\\frac{\\partial\\mathcal{L}}{\\partial q} = 0 ; y_i = 0$$ ด้วย"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea089794",
   "metadata": {},
   "source": [
    "from $$\\frac{d}{dx} log_a(x) = \\frac {1} {xlog_e {a}} = \\frac {1} {xln\\left(a\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b804c9",
   "metadata": {},
   "source": [
    "if we want to decrease error by change some value that will be combine into p \n",
    "we will write it to :\n",
    "$$ changing\\_weight\\_q\\_value\\_by = \\frac {\\partial\\mathcal{L}}{\\partial q}$$\n",
    "$$ \\frac {\\partial\\mathcal{L}}{\\partial q} = \\frac {\\partial}{\\partial q} \\left(-\\sum_{i = 0}^V \\left( y_i ln \\left(p_i\\right) \\right)\\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ac5c0",
   "metadata": {},
   "source": [
    "from the y array we found that the equation have the value only at $y_i = 1$ then we got \n",
    "$$ \\frac {\\partial\\mathcal{L}}{\\partial q} = -\\sum_{i=0}^V\\frac {\\partial\\left( y_i ln(p_i)\\right)}{\\partial p_i} \\cdot \\frac{\\partial p_i} {\\partial q}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2cb887",
   "metadata": {},
   "source": [
    "$$ \\frac {\\partial\\mathcal{L}}{\\partial q} = -\\frac {y_i}{p_i ln\\left(e\\right)} \\cdot \\frac{\\partial p_i} {\\partial q}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3679c55",
   "metadata": {},
   "source": [
    "## Softmax derivation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491cb0f7",
   "metadata": {},
   "source": [
    "from softmax equation:\n",
    "$$p_i = softmax(z_i) = \\frac{e^{z_i}}{\\sum_{k=0}^{V - 1} \\left(e^{z_k}\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f28281",
   "metadata": {},
   "source": [
    "**การหาอนุพันธ์ของ Softmax จะพิเศษกว่าขั้นตอนอื่นเนื่องจาก $softmax\\left(z_i\\right)$ ไม่ได้ขึ้นอยู่กับแค่ $z_i$ แต่จะขึ้นอยู่กับค่าของ logits ทุกตัว\n",
    "ดังนั้น**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd706a1",
   "metadata": {
    "vscode": {
     "languageId": "tex"
    }
   },
   "source": [
    "if $$logits = \\begin{bmatrix}z_0&z_1&...&z_j&...&z_{V - 1}\\end{bmatrix}$$\n",
    "\n",
    "$$\\frac{\\partial p_i} {\\partial z_m} = ?$$\n",
    "if $m = \\begin{matrix} 0, 1,..., V-1 \\end{matrix}$\n",
    "\n",
    "We start with :\n",
    "\n",
    "$$\\frac{d}{dz_m} \\frac{U}{S} = \\frac{U^\\prime S - US^\\prime}{S^2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c53af2c",
   "metadata": {},
   "source": [
    "\n",
    "$$U = e^{z_i}$$\n",
    "and \n",
    "$$S = \\sum_{k=0}^S \\left(e^{z_k}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e771a88",
   "metadata": {},
   "source": [
    "$$\\frac {\\partial U} {\\partial z_m} = \n",
    "\\begin{cases} \n",
    "    e^{z_i} & \\text{if $i = m$}\\\\ \n",
    "    0 & \\text {if $i \\neq m$} \n",
    "\\end{cases}$$\n",
    "**Or**\n",
    "$$\\frac {\\partial U} {\\partial z_m} = e^{z_i}\\delta_{i,m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9eb35",
   "metadata": {},
   "source": [
    "then in case of $i = m$ we got : \n",
    "\n",
    "$$\\frac{\\partial p_i}{\\partial z_m} = \\frac{e^{z_i} S - e^{2\\cdot z_i}}{S^2}$$\n",
    "$$\\frac{\\partial p_i}{\\partial z_m} = \\frac{e^{z_i}}{S} \\cdot \\frac{S - e^{z_i}}{S}$$\n",
    "\n",
    "finally got\n",
    "$$\\frac{\\partial p_i}{\\partial z_m} = p_i \\cdot \\left(1 - p_i\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2e3ed",
   "metadata": {},
   "source": [
    "if $i \\neq m$ :\n",
    "$$\n",
    "    \\frac{\\partial p_i}{\\partial z_m} = \\frac{0 \\cdot S - e^{z_i}e^{z_m}}{V^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial p_i}{\\partial z_m} = -\\frac{e^{z_i}e^{z_m}}{S^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b89868",
   "metadata": {},
   "source": [
    "**Or**\n",
    "$$\\frac{\\partial p_i}{\\partial z_m} = p_i \\cdot \\left(\\delta_{i,m} - p_i\\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a39cb3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b081ca3",
   "metadata": {},
   "source": [
    "## Mixing up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0de248",
   "metadata": {},
   "source": [
    "We have\n",
    "$$\\frac{\\partial p_i}{\\partial z_m} = p_i \\cdot \\left(\\delta_{i, m} - p_j\\right)$$\n",
    "และ loss function (cross-entropy) ต่อ 1 ตำแหน่ง:\n",
    "\n",
    "$$\\mathcal{L} = - \\sum_{i = 0}^{V} y_i log \\left(p_i\\right)$$\n",
    "\n",
    "โดย y มักจะเป็น one-hot (แต่ derivation นี้ใช้ได้กับ distribution ด้วย)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f1187",
   "metadata": {},
   "source": [
    "#### 1.) เริ่ม chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e69a65",
   "metadata": {},
   "source": [
    "$$\\frac {\\partial \\mathcal {L}} {\\partial z_m} =\n",
    "\\sum_{j=0}^{V - 1} \\frac{\\partial \\mathcal{L}}{\\partial p_i} \\cdot\n",
    "\\frac {\\partial p_i}{\\partial z_m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba9469",
   "metadata": {},
   "source": [
    "หา $\\frac {\\partial \\mathcal{L}}{\\partial p_i}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8566ee",
   "metadata": {},
   "source": [
    "$$\\frac {\\partial \\mathcal{L}}{\\partial p_i} = -\\frac{y_i}{p_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2312882",
   "metadata": {},
   "source": [
    "แทนกลับเข้าไป :\n",
    "$$\\frac {\\partial \\mathcal {L}} {\\partial z_m} =\n",
    "\\sum_{i=0}^{V - 1} \\left(\\left(-\\frac{y_i}{p_i} \\right)\\cdot\n",
    "p_i \\cdot \\left(\\delta_{i, m} - p_i\\right)\\right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59669cb9",
   "metadata": {},
   "source": [
    "ตัด $p_i$ ทิ้ง :\n",
    "$$\\frac {\\partial \\mathcal {L}} {\\partial z_m} =\n",
    "\\sum_{j=0}^{V - 1} \\left(-{y_i}  \\cdot \\left(\\delta_{i, m} - p_i\\right)\\right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e463e7",
   "metadata": {},
   "source": [
    "#### 2.) แยกผลรวมออกเป็น 2 ก้อน (นี่คือจุดที่ \"เคสอื่น ๆ\" จะถูกกินรวม)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b876f6",
   "metadata": {},
   "source": [
    "$$-\\sum_i y_i\\left(\\delta_{i, m} - p_m\\right) = - \\sum_i y_i \\delta_{i, m} + \\sum_i y_i p_m$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df105b0",
   "metadata": {},
   "source": [
    "สังเกตว่า $p_m$ ไม่ขึ้นกับ $i$ (สำหรับการ sum ตาม $i$) จึงสามารถดึงออกมาจากผลรวมได้:\n",
    "\n",
    "$$ \\frac {\\partial \\mathcal{L}} {\\partial z_m} = -\\sum_i y_i \\delta_{i, m} + p_m \\sum_i y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f39dc",
   "metadata": {},
   "source": [
    "#### 3.) ประเมินผลรวมของ $\\sum_i y_i \\delta_{i,m}$ และ $\\sum_i y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ffd49d",
   "metadata": {},
   "source": [
    "* $\\sum_i y_i \\delta_{i, m}$ : $\\delta_{i, m}$ ทำหน้าที่ \"เลือก\" เฉพาะตำแหน่ง $i = m$ ดังนั้น : \n",
    "$$ \\sum_i y_i \\delta_{i, m} = y_m$$\n",
    "\n",
    "* $\\sum_i y_i$ : ถ้า $y$ เป็น one-hot หรือเป็น probability distribution:\n",
    "$$ \\sum_i y_i = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7de06f",
   "metadata": {},
   "source": [
    "#### 4.) สรุปออกมาเป็น $p-y$\n",
    "\n",
    "แทนค่า : \n",
    "$$\\frac{\\partial \\mathcal {L}} {\\partial z_m} = -y_m + p_m \\cdot 1 = p_m - y_m$$\n",
    "\n",
    "ดังนั้นในรูป vector : \n",
    "$$\\frac{\\partial \\mathcal {L}} {\\partial \\vec{z}} = \\vec{p}- \\vec{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cac135",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e50c7",
   "metadata": {},
   "source": [
    "## Learn from dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645bf174",
   "metadata": {},
   "source": [
    "สมมุติในการเทรน LLM เราจะมีข้อความหนึ่งชุด แล้วตัดเป็นชิ้นยาว T = 8 tokens:\n",
    "* ถ้าใน 1 step เราใช้ข้อความแค่ชิ้นเดียว -> Batch size $B = 1$\n",
    "    * input shape: (1, 8)\n",
    "    * model จะทำนาย next-token 8 ตำแหน่ง\n",
    "    * จำนวน token ที่ฝึกต่อ step = $B \\cdot T = 8$ \n",
    "\n",
    "ตัวอย่าง batch จริง ๆ (หลายชิ้นพร้อมกัน)\n",
    "\n",
    "สมมติเราเตรียมชิ้นข้อความ (แต่ละชิ้นยาว 8 tokens) ได้ 4 ชิ้น : \n",
    "* Step หนึ่งใช้ 4 ชิ้นพร้อมกัน -> Batch size $B = 4$\n",
    "    * input shape: (4, 8)\n",
    "    * จำนวน token ที่ฝึกต่อ step = $4 \\cdot 8 = 32$\n",
    "\n",
    "**ผลที่ได้คือ** : gradient ที่ได้ต่อ step จะมีความนิ่งขึ้น เพราะมาจากตัวอย่างที่มากขึ้น"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca7a8b",
   "metadata": {},
   "source": [
    "\n",
    "* ตอนที่เราทำการเทรนทีละ Sequence หรือ ฺ$B = 1$ ใช้สมการเดิมได้ไม่มีปัญหา\n",
    "\n",
    "* แต่ถ้าเอา 32 sequence มารวมกันเป็น batch -> $B = 32$\n",
    "\n",
    "ทำให้ shape ที่ได้เป็น : \n",
    "\n",
    "* logits $Z: (B, T, V)$\n",
    "* probs $P: (B, T, V)$\n",
    "* targets $Y: (B, T, V)$ (one-hot) หรือ (B, T)(index)\n",
    "\n",
    "---\n",
    "\n",
    "ทำให้ตอนคิด Loss function จะต้องคิดเป็นค่าเฉลี่ย (mean) (เป็นที่นิยมใช้) แล้วได้สมการเป็น\n",
    "\n",
    "$$\\mathcal {L} = \\frac {1} {B \\cdot T} \\sum_{b=1}^B \\sum_{t=1}^T \\left(-ln \\left(p_{b, t, y_{b,t}}\\right)\\right)$$\n",
    "\n",
    "แล้วทำให้ gradient มี factor $\\frac {1} {B \\cdot T}$ ติดมาด้วย : \n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}} {\\partial \\vec{Z}} = \\frac{\\vec{P} - \\vec{Y}}{B \\cdot T} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbcedb",
   "metadata": {},
   "source": [
    "### 1) for example Vocab มี 6 ตัว\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2754bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab = [\"<PAD>\", \"I\", \"You\", \"love\", \"a\", \"cat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a2774",
   "metadata": {},
   "source": [
    "มีทั้งหมด 2 ประโยค (Batch size $B = 2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d93a66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceA = \"I love a cat\"\n",
    "sentenceB = \"You love a cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf20c2",
   "metadata": {},
   "source": [
    "เราจะตั้ง sequence length ที่ใช้เทรนเป็น $T = 3$ (เอาแค่ 3 ตัวแรกเป็น input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df11206",
   "metadata": {},
   "source": [
    "### 2 สร้าง X (input) และ Y (output) ด้วยการเลื่อนไปทางซ้าย 1 ระดับ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb05416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = [1, 3, 4]\n",
    "Y_a = [3, 4, 5]\n",
    "\n",
    "X_b = [2, 3, 4]\n",
    "Y_b = [3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c73fe",
   "metadata": {},
   "source": [
    "### 3) เขียนเป็น Matrix (B, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49a6b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([X_a, X_b]);\n",
    "Y = np.array([Y_a, Y_b]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824f76be",
   "metadata": {},
   "source": [
    "### 4) Model ให้ logits ออกมาเป็น (B, T, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d921df7",
   "metadata": {},
   "source": [
    "logits หมายถึงคะแนนดิบก่อน softmax\n",
    "$$ Z \\in \\mathbb{R}^{2 \\times 3 \\times 6}$$\n",
    "ในกรณีนี้มี Vocab size (V) = 6\n",
    "มี ฺBatch size = 2 \n",
    "มี token size = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dda70d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_0 = np.array([\n",
    "    [-1, .2, -.3, 2.5, .1, -.7],\n",
    "    [-.4, -.2, -.5, .1, 2.2, 0],\n",
    "    [-.8, -.3, -.2, 0, .4, 2.6]\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c02b06e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_1 = np.array([\n",
    "    [-1.1, -.1, 0, 2.3, .2, -.6], \n",
    "    [-.5, -.3, -.4, .2, 2.4, -.1],\n",
    "    [-.9, -.4, -.1, .1, .3, 2.5]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6b9cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([Z_0, Z_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586fff32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e9535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5313d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 5\n",
    "T = 6\n",
    "V = 20\n",
    "\n",
    "p = np.array([\n",
    "    [.1, .2, .4, .1, 0, .1], \n",
    "    [.1, .1, .2, 0, 5, .1]]);\n",
    "y = np.array([\n",
    "    [0, 0, 1, 0, 0, 0], \n",
    "    [0, 0, 0, 0, 1, 0]\n",
    "    ]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fa7a58",
   "metadata": {},
   "source": [
    "$$\\text{softmax}\\left(\\text{logits}\\right) =  \\frac{e^{logits_i-logits_{max}}}{\\sum_{i = 0}^{V-1} e^{logits_i-logits_{max}}}$$\n",
    "\n",
    "When $V$ is vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94889913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis = -1):\n",
    "    x = x - np.max(x, axis = axis, keepdims=True)\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e, axis = axis, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d0b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_head_forward(H, W, b):\n",
    "    #H: (T, d), W: (d, V), b: (V,)\n",
    "    Z = H @ W + b # (T, V) probs\n",
    "    P = softmax(Z, axis = 1) # (T, V) probs\n",
    "\n",
    "    return Z, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "295c097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossAndSoftmaxBackward(y, p):\n",
    "    return p - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f63a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1,  0.2, -0.6,  0.1,  0. ,  0.1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlossBydz = lossAndSoftmaxBackward(y, p)\n",
    "dlossBydz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7875f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
